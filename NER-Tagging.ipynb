{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d56b85-e7ef-452f-bc6e-69da6d6aa4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da4c031-d947-403c-ac89-489687a1aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'O': 0,\n",
    "    'B-ORG': 1,\n",
    "    'I-ORG': 2,\n",
    "    'B-PER': 3,\n",
    "    'I-PER': 4,\n",
    "    'B-LOC': 5,\n",
    "    'I-LOC': 6,\n",
    "    'B-MISC': 7,\n",
    "    'I-MISC': 8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59584ae5-5a3b-45ee-8540-f160bfec7a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'tokens'],\n",
       "    num_rows: 3684\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "def file_to_dataset_for_test(file_path):\n",
    "    tokens = []\n",
    "    data = {'id': [], 'tokens': []}\n",
    "    current_id = 0\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            if line.strip():  # If the line is not empty, process it\n",
    "                parts = line.strip().split(' ')\n",
    "                if len(parts) == 2:  # Ensure the line has three parts: index, word\n",
    "                    _, token = parts\n",
    "                    tokens.append(token)\n",
    "            else:  # If the line is empty, it indicates the end of a sentence\n",
    "                if tokens:  # If there are tokens collected, save the current sentence\n",
    "                    data['id'].append(str(current_id))\n",
    "                    data['tokens'].append(tokens)\n",
    "                    current_id += 1\n",
    "                    tokens = []\n",
    "                \n",
    "        # Add the last sentence if the file doesn't end with a blank line\n",
    "        if tokens:\n",
    "            data['id'].append(str(current_id))\n",
    "            data['tokens'].append(tokens)\n",
    "    \n",
    "    dataset = Dataset.from_dict(data)\n",
    "    return dataset\n",
    "\n",
    "test_dataset = file_to_dataset_for_test('data/test')\n",
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f1e9b6b-df0d-49c3-a802-8b37f263f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_dataset(file_path, label_mapping):\n",
    "    tokens = []\n",
    "    labels = []\n",
    "    data = {'id': [], 'tokens': [], 'labels': []}\n",
    "    current_id = 0\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            if line.strip():  # If the line is not empty, process it\n",
    "                parts = line.strip().split(' ')\n",
    "                if len(parts) == 3:  # Ensure the line has three parts: index, word, NER tag\n",
    "                    _, token, label = parts\n",
    "                    tokens.append(token)\n",
    "                    labels.append(label_mapping[label])  # Convert label to integer\n",
    "            else:  # If the line is empty, it indicates the end of a sentence\n",
    "                if tokens:  # If there are tokens collected, save the current sentence\n",
    "                    data['id'].append(str(current_id))\n",
    "                    data['tokens'].append(tokens)\n",
    "                    data['labels'].append(labels)\n",
    "                    current_id += 1\n",
    "                    tokens, labels = [], []  # Reset for the next sentence\n",
    "                \n",
    "        # Add the last sentence if the file doesn't end with a blank line\n",
    "        if tokens:\n",
    "            data['id'].append(str(current_id))\n",
    "            data['tokens'].append(tokens)\n",
    "            data['labels'].append(labels)\n",
    "    \n",
    "    dataset = Dataset.from_dict(data)\n",
    "    return dataset\n",
    "\n",
    "train_path = 'data/train'\n",
    "validation_path = 'data/dev'\n",
    "\n",
    "# Converting files to Hugging Face Datasets\n",
    "train_dataset = file_to_dataset(train_path, label_mapping)\n",
    "validation_dataset = file_to_dataset(validation_path, label_mapping)\n",
    "\n",
    "# Combining datasets into a DatasetDict\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': validation_dataset\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c160d0-f9ce-43bc-9b4c-a3dd3dfbf4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2idx = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "idx2tag = {v:k for k, v in tag2idx.items()}\n",
    "idx2tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46f42b36-3dbb-410c-9f96-ebf3bb4426b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from itertools import chain\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "import numpy as np\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "def calculate_metrics(labels, preds):\n",
    "    # Flatten the lists\n",
    "    flat_labels = list(chain(*labels))\n",
    "    flat_preds = list(chain(*preds))\n",
    "\n",
    "    # Initialize counts\n",
    "    TP = FP = FN = 0\n",
    "\n",
    "    # Calculate TP, FP, FN\n",
    "    for true_label, pred_label in zip(flat_labels, flat_preds):\n",
    "        if true_label != 'O':  # Entity present in the ground truth\n",
    "            if true_label == pred_label:\n",
    "                TP += 1  # Correctly identified entity\n",
    "            else:\n",
    "                FN += 1  # Missed entity\n",
    "        if pred_label != 'O':  # Entity predicted\n",
    "            if true_label != pred_label:\n",
    "                FP += 1  # Incorrectly identified entity\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = (TP / (TP + FP) if (TP + FP) else 0) * 100\n",
    "    recall = (TP / (TP + FN) if (TP + FN) else 0) * 100\n",
    "    f1 = (2 * (precision * recall) / (precision + recall)) if (precision + recall) else 0\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d32c3f46-43fa-4645-91ef-70358907f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'preds': [], 'labels': [], 'mask': [], 'loss': []}\n",
    "def eval_dataloader(loader, model, loss_fn, verbose=False, name=''):\n",
    "    \n",
    "    # using cuda only as required. Only GPU\n",
    "    for batch in loader:\n",
    "        input_ids = batch['input_ids'].to('cuda')\n",
    "        labels = batch['labels'].to('cuda')\n",
    "        mask = batch['mask'].to('cuda')\n",
    "        \n",
    "        predictions = model(input_ids)\n",
    "        # print(predictions[0])\n",
    "        loss = loss_fn(predictions.transpose(-1, -2), labels.to(torch.long))\n",
    "        loss = torch.masked_select(loss, mask.bool()).mean()\n",
    "        \n",
    "        d['preds'].extend(predictions.argmax(-1).tolist())\n",
    "        d['labels'].extend(labels.tolist())\n",
    "        d['mask'].extend(mask.tolist())\n",
    "        d['loss'].append(loss.item())\n",
    "        \n",
    "    preds, labels = [], []\n",
    "    # print(d['preds'])\n",
    "    # create eval fun that support data\n",
    "    for i in range(len(d['preds'])):\n",
    "        pred = [idx2tag[k] for k, m in zip(d['preds'][i], d['mask'][i]) if m > 0]\n",
    "        label = [idx2tag[k] for k, m in zip(d['labels'][i], d['mask'][i]) if m > 0]\n",
    "        preds.append(pred)\n",
    "        labels.append(label)\n",
    "\n",
    "    \n",
    "    precision, recall, f1 = calculate_metrics(labels, preds)\n",
    "    # print/return the average loss and f1\n",
    "    print(f'name: {name}, f1: {f1}, precision: {precision}, recall: {recall}, loss: {sum(d[\"loss\"])/len(d[\"loss\"])}')\n",
    "    return (f1, precision, recall), sum(d['loss'])/len(d['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8394e542-bf4a-45ac-ab0b-0ac2e232c04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab count 8127\n"
     ]
    }
   ],
   "source": [
    "# iterate on tokens and count using Counter class\n",
    "word_frequency = Counter(itertools.chain(*dataset['train']['tokens']))\n",
    "word2idx = {\n",
    "    word: frequency\n",
    "    for word, frequency in word_frequency.items()\n",
    "    if frequency >= 3\n",
    "}\n",
    "\n",
    "word2idx = {\n",
    "    word: index\n",
    "    for index, word in enumerate(word2idx.keys(), start=2)\n",
    "}\n",
    "print('vocab count', len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "199ccd01-84a4-4230-ad13-b99969806853",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx['[PAD]'] = 0\n",
    "word2idx['[UNK]'] = 1\n",
    "idx2word = {v:k for k, v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca0dc0bf-ea69-412a-834f-b928b617cb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14987 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3684 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_word_to_id(sample):\n",
    "    return {\n",
    "        'input_ids': [\n",
    "        (word2idx[token] if token in word2idx else word2idx['[UNK]'])\n",
    "        for token in sample['tokens']\n",
    "        ]\n",
    "}\n",
    "dataset_ids = dataset.map(convert_word_to_id)\n",
    "test_dataset_ids = test_dataset.map(convert_word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9b044d6-cb55-4375-91b1-b62dca3d9c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14987 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3684 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MaxLenFinder:\n",
    "    def __init__(self):\n",
    "        self.max_len = 0\n",
    "\n",
    "    def get_max_len(self, sample):\n",
    "        if len(sample['tokens']) > self.max_len: \n",
    "            self.max_len = len(sample['tokens'])\n",
    "        # It's important for the map function that we return the sample unchanged.\n",
    "        return sample\n",
    "\n",
    "# Usage for dataset 1\n",
    "max_len_finder = MaxLenFinder()\n",
    "dataset.map(max_len_finder.get_max_len)\n",
    "train_max_len = max_len_finder.max_len\n",
    "\n",
    "test_len_finer = MaxLenFinder()\n",
    "test_dataset.map(max_len_finder.get_max_len)\n",
    "test_max_len = max_len_finder.max_len\n",
    "\n",
    "\n",
    "max_len = max(train_max_len, test_max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99154d66-096a-4a29-a39c-aa000f3a029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class. NERDataset\n",
    "class NER_Dataset_test(Dataset):\n",
    "    def __init__(self, dataset, vocab, max_len=128):\n",
    "        self.dataset = dataset\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return self.dataset.num_rows\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        input_ids = data['input_ids']\n",
    "        mask = [1] * len(data['input_ids'])\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.int32),\n",
    "            'mask': torch.tensor(mask, dtype=torch.int8)\n",
    "        }\n",
    "\n",
    "NERtest_dataset = NER_Dataset_test(test_dataset_ids, word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40548818-6632-41bc-95be-4041eaab8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class. NERDataset\n",
    "class NER_Dataset(Dataset):\n",
    "    def __init__(self, dataset, vocab, max_len=128):\n",
    "        self.dataset = dataset\n",
    "        self.vocab = vocab\n",
    "        self.max_len = max_len\n",
    "    def __len__(self):\n",
    "        return self.dataset.num_rows\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        input_ids = data['input_ids']\n",
    "        label = data['labels']\n",
    "        mask = [1] * len(data['input_ids'])\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.int32),\n",
    "            'labels': torch.tensor(label, dtype=torch.int8),\n",
    "            'mask': torch.tensor(mask, dtype=torch.int8)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbc3b10a-35f1-4392-95a9-2d0f203c6e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets. Train, validation, test\n",
    "train_dataset = NER_Dataset(dataset_ids['train'], word2idx)\n",
    "val_dataset = NER_Dataset(dataset_ids['validation'], word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0b5b8c7-f735-4e38-93cc-e19e92230b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define collate function. Passing the collate function can inputs\n",
    "def collate_fn(inputs, pad_token_id = 0):\n",
    "    return {\n",
    "        'input_ids': nn.utils.rnn.pad_sequence([i['input_ids'] for i in inputs], batch_first=True, padding_value=pad_token_id),\n",
    "        'labels': nn.utils.rnn.pad_sequence([i['labels'] for i in inputs], batch_first=True, padding_value=pad_token_id),\n",
    "        'mask': nn.utils.rnn.pad_sequence([i['mask'] for i in inputs], batch_first=True, padding_value=pad_token_id),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ace930ff-f8f1-4117-9121-9fe76496c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def collate_fn_test(batch):\n",
    "    input_ids = [item['input_ids'] for item in batch]\n",
    "    masks = [item['mask'] for item in batch]\n",
    "\n",
    "    input_ids_padded = pad_sequence(input_ids, batch_first=True, padding_value=0)\n",
    "    masks_padded = pad_sequence(masks, batch_first=True, padding_value=0)\n",
    "\n",
    "    return {'input_ids': input_ids_padded, 'mask': masks_padded}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6c40147-ce0a-4dd2-a6e7-304936f87338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader\n",
    "batch_size=32\n",
    "train_loader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, collate_fn=collate_fn, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f48594e7-ec8e-4df8-8e22-6578d5a767c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(NERtest_dataset, collate_fn=collate_fn_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff783b86-4484-4a7f-87d6-84424cdf3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim, embed_dim=100, lstm_dim=256, dropout=0.50, linear_dim=128):\n",
    "                super().__init__()\n",
    "                self.input_dim = input_dim\n",
    "                self.embed_dim = embed_dim\n",
    "                self.embedding = nn.Embedding(self.input_dim, self.embed_dim)\n",
    "                self.lstm_dim = lstm_dim\n",
    "                self.lstm = nn.LSTM(self.embed_dim, self.lstm_dim, batch_first=True, bidirectional=True)\n",
    "                self.dropout = nn.Dropout(dropout)\n",
    "                self.linear_dim = linear_dim\n",
    "                self.fc2 = nn.Linear(self.lstm_dim * 2, self.linear_dim)\n",
    "                self.elu = nn.ELU()\n",
    "                self.output_dim = output_dim\n",
    "                self.fc3 = nn.Linear(self.linear_dim, self.output_dim)\n",
    "            \n",
    "        def forward(self, input_ids):\n",
    "                batch_size = input_ids.shape[0]\n",
    "                emds = self.embedding(input_ids)\n",
    "                h0 = torch.randn(2, batch_size, self.lstm_dim).to(input_ids.device)\n",
    "                c0 = torch.randn(2, batch_size, self.lstm_dim).to(input_ids.device)\n",
    "                output, (hn, cn) = self.lstm(emds, (h0, c0))\n",
    "                output = self.dropout(output)\n",
    "                linear_out = self.fc2(output)\n",
    "                linear_out = self.dropout(linear_out)\n",
    "                elu_out = self.elu(linear_out)\n",
    "                results = self.fc3(elu_out)\n",
    "                return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c5b4ee1-bfee-40dc-95b4-f496b4154cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm_model = BiLSTM(input_dim=len(word2idx), output_dim=len(tag2idx)).to(device)\n",
    "def create_hyperparameters(model, epochs):\n",
    "        loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=1e-8)\n",
    "        num_epochs = epochs\n",
    "        return loss_fn, optimizer, scheduler, num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c44cedb-dc7d-4644-a519-5a035b9d2b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: test, f1: 3.2961477536988983, precision: 1.927511381777331, recall: 11.368127397419505, loss: 2.228275550614803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3.2961477536988983, 1.927511381777331, 11.368127397419505),\n",
       " 2.228275550614803)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn, optimizer, scheduler, num_epochs = create_hyperparameters(bilstm_model, 10)\n",
    "eval_dataloader(val_loader, bilstm_model, loss_fn=loss_fn, name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4421bd00-47b2-4a4a-b1d1-c5516ac86ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(loss_fn, optimizer, scheduler, num_epochs, model, train_loader):\n",
    "        losses = []\n",
    "        vlosses = []\n",
    "        lrs = []\n",
    "        for epoch in range(num_epochs):\n",
    "                model.train()\n",
    "                total_loss = 0.0\n",
    "                loss = 0.0\n",
    "                pbar = tqdm(train_loader)\n",
    "                for batch in pbar:\n",
    "                        input_ids = batch['input_ids'].to(device)\n",
    "                        labels = batch['labels'].to(device)\n",
    "                        mask = batch['mask'].to(device)\n",
    "                        optimizer.zero_grad()\n",
    "                        predictions = model(input_ids)\n",
    "                        loss = loss_fn(predictions.transpose(-1, -2), labels.to(torch.long))\n",
    "                        loss = torch.masked_select(loss, mask.bool()).mean()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        total_loss += loss.item()\n",
    "                        pbar.set_postfix({'loss': loss.item()})\n",
    "                lrs.append(scheduler.get_last_lr())\n",
    "                scheduler.step()\n",
    "                average_loss = total_loss / len(train_loader)\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}] - Loss: {average_loss:.4f}')\n",
    "                model.eval()\n",
    "                f1, l = eval_dataloader(train_loader, model, loss_fn=loss_fn, name='train')\n",
    "                losses.append(l)\n",
    "        return losses, vlosses, lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd8def5f-3849-4b34-9799-1e5437dc2d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258f9f1bb9384691afd7b651fc151f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25] - Loss: 0.4628\n",
      "name: train, f1: 39.19411827105892, precision: 30.05644343766817, recall: 56.3147774703372, loss: 0.5883450008361604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2bd08b9a8a411fb050ed0798c8a5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25] - Loss: 0.1878\n",
      "name: train, f1: 55.68650496847954, precision: 47.168547664515664, recall: 67.95889892944228, loss: 0.3718691422731225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c6a06116204bfabc2ce37d6c3ef2ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25] - Loss: 0.1178\n",
      "name: train, f1: 65.29989112082433, precision: 57.97492294760437, recall: 74.74352490698263, loss: 0.27679784102291655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb323fe308a4f8a8ba23bd825faa857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25] - Loss: 0.0870\n",
      "name: train, f1: 71.31294655259059, precision: 65.05444315360259, recall: 78.90381626662062, loss: 0.22274377053129657\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0a2dc7bbb7455f93a223339164f0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25] - Loss: 0.0661\n",
      "name: train, f1: 75.56167085300655, precision: 70.17496751425297, recall: 81.84410965339059, loss: 0.18697064916466452\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82fdcc744cbb4d5fa61830322c24234d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25] - Loss: 0.0549\n",
      "name: train, f1: 78.71219332048106, precision: 73.96592467734206, recall: 84.10934835409023, loss: 0.1612691531094665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c6d9308d824e0f8391d7547a7a9619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25] - Loss: 0.0441\n",
      "name: train, f1: 81.15035171109936, precision: 76.91451081673219, recall: 85.87993714156109, loss: 0.14190986242856696\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175ad0ce991b48629d8a73e4f66eacf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25] - Loss: 0.0358\n",
      "name: train, f1: 83.08023825496535, precision: 79.26683799641178, recall: 87.27909534538543, loss: 0.12665787590589664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4b10282efa4c7eb06504bf63ef40d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25] - Loss: 0.0309\n",
      "name: train, f1: 84.6502016971428, precision: 81.17403657026298, recall: 88.43741071145116, loss: 0.11442547418087329\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4dc31c002b43bbbb22b1ee8b3d493a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25] - Loss: 0.0279\n",
      "name: train, f1: 85.94575011330186, precision: 82.7680258102859, recall: 89.37722221108034, loss: 0.10445767650376303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0368095d1408427ba577a680ec64dc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25] - Loss: 0.0246\n",
      "name: train, f1: 87.03355894071602, precision: 84.0985829432228, recall: 90.18079963244891, loss: 0.0961708495179238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71391e9499fc4ab5a892120bb3b81574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25] - Loss: 0.0228\n",
      "name: train, f1: 87.96037839606291, precision: 85.22013780390482, recall: 90.88269774332984, loss: 0.08913552586473161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355e5cf39c584bec9b64030a636c67cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25] - Loss: 0.0217\n",
      "name: train, f1: 88.76137465884088, precision: 86.20341050556024, recall: 91.4757891843728, loss: 0.08306508978481508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2485098bf29d4a668ee6673c5eb46273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25] - Loss: 0.0191\n",
      "name: train, f1: 89.45176515386851, precision: 87.05114827636648, recall: 91.98854092600035, loss: 0.07782477639869759\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e11d41c4e54e3eb8f2021af2a9bd62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25] - Loss: 0.0179\n",
      "name: train, f1: 90.07030322133976, precision: 87.80843817335095, recall: 92.4517764151234, loss: 0.07317819356272341\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acd74f8dcb941438d10cb59d3b00558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25] - Loss: 0.0166\n",
      "name: train, f1: 90.61672458811984, precision: 88.47698358578032, recall: 92.86252622941635, loss: 0.0690941501688288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcd63e9fcb764a45a17f7240b2c43dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25] - Loss: 0.0150\n",
      "name: train, f1: 91.10150702766558, precision: 89.073549579389, recall: 93.22395774806158, loss: 0.0654524054361975\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e883cf7ff74bf4836a927b180d935b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25] - Loss: 0.0143\n",
      "name: train, f1: 91.54090110291568, precision: 89.61232351540208, recall: 93.5543156570005, loss: 0.062161642055134476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76e41ca2cd54a608583cd206d4686a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25] - Loss: 0.0139\n",
      "name: train, f1: 91.93664458418806, precision: 90.09688829650895, recall: 93.85310182783559, loss: 0.05921358211919012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61c93ba8729d4522a08d93ffe1faf851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25] - Loss: 0.0127\n",
      "name: train, f1: 92.29434557438461, precision: 90.53341443271356, recall: 94.12513796969526, loss: 0.05654616384807784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275fbf77c6da4179a04fae35c892848b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25] - Loss: 0.0131\n",
      "name: train, f1: 92.6189545994693, precision: 90.9331973075417, recall: 94.3683950098548, loss: 0.05413599193343904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63397576f5f04eb2808cd29f5a048c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25] - Loss: 0.0132\n",
      "name: train, f1: 92.91476110885635, precision: 91.29765604196369, recall: 94.59018492533157, loss: 0.051941631767740776\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75ef1aa3770c4328b4d7453994f9e35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25] - Loss: 0.0122\n",
      "name: train, f1: 93.18969976162491, precision: 91.63616825111889, recall: 94.79681452061163, loss: 0.049897433566591674\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fd5f7a26ad4d74ae9fb0c096c39025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25] - Loss: 0.0117\n",
      "name: train, f1: 93.43814821742814, precision: 91.93898760502552, recall: 94.9870099983649, loss: 0.04806991260588346\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcf1ce96be643929aafe70cc6656885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25] - Loss: 0.0120\n",
      "name: train, f1: 93.6708962213383, precision: 92.22424634586812, recall: 95.1636542984699, loss: 0.046346160613460904\n"
     ]
    }
   ],
   "source": [
    "losses, vlosses, lrs = training_loop(*create_hyperparameters(bilstm_model, 25), bilstm_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76abbc20-1c80-4114-a93a-612d34875c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models\\blstm1\n"
     ]
    }
   ],
   "source": [
    "models_dir = 'models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# It's good practice to include the '.pt' extension for PyTorch model files\n",
    "model_path = os.path.join(models_dir, 'blstm1.pt')  # Updated to include the .pt extension\n",
    "\n",
    "# Save the model state dictionary, overwriting any existing file\n",
    "torch.save(bilstm_model.state_dict(), model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36c3991c-f441-4e48-8d51-e546c0d94769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: test, f1: 93.57272255628227, precision: 92.15702041828331, recall: 95.03259889367612, loss: 0.048918584548751\n"
     ]
    }
   ],
   "source": [
    "# F1, precision, and recall result for eval\n",
    "f1 = eval_dataloader(val_loader, bilstm_model.eval(), loss_fn=loss_fn, name='Dev', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d6c4c40-da85-499f-9578-14e8f8dd8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions_to_file(dataloader, model, idx2tag, file_path):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad(), open(file_path, 'w', encoding='utf-8') as file:\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to('cuda')\n",
    "            # No labels are needed, as we're just predicting\n",
    "            mask = batch['mask'].to('cuda')\n",
    "\n",
    "            predictions = model(input_ids)\n",
    "            predictions = predictions.argmax(-1)  # Get the most likely prediction indices\n",
    "\n",
    "            # Convert the batch of predictions to tags\n",
    "            for sentence_preds, sentence_mask in zip(predictions, mask):\n",
    "                idx = 1  # Start index for each new sentence\n",
    "                for pred, m in zip(sentence_preds, sentence_mask):\n",
    "                    if m == 0:  # Skip padding\n",
    "                        continue\n",
    "                    tag = idx2tag[int(pred)]\n",
    "                    \n",
    "                    file.write(f\"{idx} TOKEN {tag}\\n\")\n",
    "                    idx += 1\n",
    "                file.write(\"\\n\")  # Separate sentences by a blank line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce97ac4e-e046-4c4d-8876-3d85fed15a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_predictions(loader, model, idx2tag, dataset_partition, output_file, temp_file='temp_predictions.txt'):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - loader: DataLoader for the dataset.\n",
    "    - model: The model to make predictions.\n",
    "    - idx2tag: Dictionary to map prediction indices to tags.\n",
    "    - dataset_partition: Part of the dataset to use (e.g., 'validation', 'test').\n",
    "    - output_file: File path for the output file.\n",
    "    \"\"\"\n",
    "    # Step 1: Write predictions to a temporary file\n",
    "    write_predictions_to_file(loader, model, idx2tag, temp_file)\n",
    "\n",
    "    # Step 2: Read tokens from the dataset\n",
    "    token_lists = [dataset_partition[i]['tokens'] for i in range(len(dataset_partition))]\n",
    "\n",
    "    # Step 3: Read and process the temporary file content\n",
    "    with open(temp_file, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    blocks = content.strip().split('\\n\\n')\n",
    "    assert len(blocks) == len(token_lists), \"The number of blocks and token lists do not match.\"\n",
    "\n",
    "    processed_blocks = []\n",
    "    for block, tokens in zip(blocks, token_lists):\n",
    "        lines = block.split('\\n')\n",
    "        new_lines = []\n",
    "        for line, token in zip(lines, tokens):\n",
    "            new_line = line.replace('TOKEN', token)\n",
    "            new_lines.append(new_line)\n",
    "        processed_blocks.append('\\n'.join(new_lines))\n",
    "\n",
    "    output_content = '\\n\\n'.join(processed_blocks)\n",
    "\n",
    "    # Step 4: Write the processed content to the specified output file\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(output_content)\n",
    "\n",
    "    # Step 5: Clean up the temporary file\n",
    "    if os.path.exists(temp_file):\n",
    "        os.remove(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "688257d0-4815-464b-b274-1e7c2195d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "process_predictions(val_loader, bilstm_model, idx2tag, dataset['validation'], 'dev1.out')\n",
    "process_predictions(test_loader, bilstm_model, idx2tag, test_dataset, 'test1.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64e4b239-af9d-451a-8aea-b26b377802ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = 'glove.6B.100d.txt'\n",
    "glove = {}\n",
    "with open(glove_path, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        glove[word] = [-0.1, *vector]\n",
    "        if word[0].upper() != word[0]:\n",
    "            glove[word[0].upper()+word[1:]] = [0.1, *vector]\n",
    "            if len(word) > 1:\n",
    "                glove[word.upper()] = [0.2, *vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9fe1b2d-dcf1-438a-90b8-1a45be0a2320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 101])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pu_emb = torch.zeros(2, 101)\n",
    "pu_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4acf6be3-0cf5-4298-b4c6-45f3191b548d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0049), tensor(0.4074))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_tensored = torch.tensor(list(glove.values()))\n",
    "glove_tensored.mean(), glove_tensored.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ffecdad-e581-42bc-b82a-86e345b334eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = torch.cat([pu_emb, glove_tensored], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "045cd89a-f351-48a6-b416-fd28e743e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gword2idx = {\n",
    "    word: index\n",
    "    for index, word in enumerate(glove.keys(), start=2)\n",
    "}\n",
    "gword2idx['[PAD]'] = 0\n",
    "gword2idx['[UNK]'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79f3fae2-5db9-44e6-9fa3-8b30aab59cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14987 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3466 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert all tokens to their respective indx\n",
    "def gconvert_word_to_id(sample):\n",
    "    return {\n",
    "        'input_ids': [\n",
    "            (gword2idx[token] if token in gword2idx else gword2idx['[UNK]'])\n",
    "            for token in sample['tokens']\n",
    "    ]\n",
    "}\n",
    "gdataset_ids = dataset.map(gconvert_word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "787c36b1-302f-4f69-8a6d-621135fc944c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3684 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_gdataset_ids = test_dataset.map(gconvert_word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9e4621b-56e8-442e-a26d-5b0d0533bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtrain_dataset = NER_Dataset(gdataset_ids['train'], gword2idx)\n",
    "gval_dataset = NER_Dataset(gdataset_ids['validation'], gword2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6139094e-65a8-4df3-b21c-7ec56282c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtest_dataset = NER_Dataset_test(test_gdataset_ids, gword2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b838e26f-137b-4f7f-96e2-2c4a16828ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader\n",
    "gtrain_loader = DataLoader(gtrain_dataset, collate_fn=collate_fn, batch_size=batch_size, shuffle=True)\n",
    "gval_loader = DataLoader(gval_dataset, collate_fn=collate_fn, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a803032e-7b31-4bc2-9dd9-6b893f7d2f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "gtest_loader = DataLoader(gtest_dataset, collate_fn=collate_fn_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b9f363de-2426-4acd-9cb9-12e6f1558761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveBiLSTM(nn.Module):\n",
    "    def __init__(self, output_dim, glove_embeddings, embed_dim=101, lstm_dim=256,\n",
    "                dropout=0.50, linear_dim=128):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embedding = nn.Embedding.from_pretrained(glove_embeddings, freeze=True)\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.lstm = nn.LSTM(self.embed_dim, self.lstm_dim, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_dim = linear_dim\n",
    "        self.fc2 = nn.Linear(self.lstm_dim * 2, self.linear_dim)\n",
    "        self.elu = nn.ELU()\n",
    "        self.output_dim = output_dim\n",
    "        self.fc3 = nn.Linear(self.linear_dim, self.output_dim)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        batch_size = input_ids.shape[0]\n",
    "        emds = self.embedding(input_ids)\n",
    "        h0 = torch.randn(2, batch_size, self.lstm_dim).to(input_ids.device)\n",
    "        c0 = torch.randn(2, batch_size, self.lstm_dim).to(input_ids.device)\n",
    "        output, (hn, cn) = self.lstm(emds, (h0, c0))\n",
    "        output = self.dropout(output)\n",
    "        linear_out = self.fc2(output)\n",
    "        linear_out = self.dropout(linear_out)\n",
    "        elu_out = self.elu(linear_out)\n",
    "        results = self.fc3(elu_out)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43649c1d-01b3-4bbc-94da-9cf4f1b3a859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a0e12755634d16b65ca66b67f425de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25] - Loss: 0.2495\n",
      "name: train, f1: 93.30477285953549, precision: 92.02812082642116, recall: 94.61734365926209, loss: 0.05088261464442016\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732e2d92af08468a853d9986fc816516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/25] - Loss: 0.1082\n",
      "name: train, f1: 93.22215527924445, precision: 92.03826097817375, recall: 94.43690347908459, loss: 0.05145425501858018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48ab7c55859442a986f15172cb6a006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/25] - Loss: 0.0816\n",
      "name: train, f1: 93.22498549367319, precision: 92.10731707317073, recall: 94.37011160231242, loss: 0.0514117906873285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01795bc8d7b544b6a1a42f5df0913a1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/25] - Loss: 0.0662\n",
      "name: train, f1: 93.29199415925093, precision: 92.2163120050031, recall: 94.39306766966698, loss: 0.050918564567029256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d679f662670e489c907787793d1c6ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/25] - Loss: 0.0562\n",
      "name: train, f1: 93.37339618860199, precision: 92.33140934454148, recall: 94.43916972236774, loss: 0.050274979134563046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f40fccb2da425aa1439a1d8e18ef98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/25] - Loss: 0.0475\n",
      "name: train, f1: 93.47320508067892, precision: 92.46003621255035, recall: 94.50882438773787, loss: 0.04950516607013134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d024368527724a9aa7e8eaf462e82aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25] - Loss: 0.0407\n",
      "name: train, f1: 93.58757728880354, precision: 92.59828993296665, recall: 94.59823131046772, loss: 0.048618305919922\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fe2bd9ab974f8d80f00432ecb1e94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/25] - Loss: 0.0362\n",
      "name: train, f1: 93.71215112217936, precision: 92.76075463919297, recall: 94.68326575342466, loss: 0.04765335966539777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6765fad509f4a5e91bc777bd730bb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25] - Loss: 0.0320\n",
      "name: train, f1: 93.84542640193314, precision: 92.9225844033803, recall: 94.78678230785209, loss: 0.0466542746977541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ea719348ef47ca894648f4bbbe121a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25] - Loss: 0.0280\n",
      "name: train, f1: 93.97108730669838, precision: 93.07193987144291, recall: 94.88777714441252, loss: 0.0456862085998661\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8a8fc8680e49f2a0b877e66b7e8622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25] - Loss: 0.0267\n",
      "name: train, f1: 94.10139005581586, precision: 93.22979600540194, recall: 94.98943475539005, loss: 0.04470715560675574\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17379a2838a4a32b0cb6e531d2cc2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/25] - Loss: 0.0235\n",
      "name: train, f1: 94.22795883854474, precision: 93.3807473905476, recall: 95.0906839536747, loss: 0.043738315638063484\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a43965918864de1b9a0f6bd357aa4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25] - Loss: 0.0212\n",
      "name: train, f1: 94.35213886932382, precision: 93.52688057599468, recall: 95.19209056788014, loss: 0.04280115883456432\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690498e26401497aa3454d239c1cbb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/25] - Loss: 0.0194\n",
      "name: train, f1: 94.46872060692374, precision: 93.658963664759, recall: 95.29260166125975, loss: 0.04192177358612203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483ee258fc04448b987d532d72812239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25] - Loss: 0.0194\n",
      "name: train, f1: 94.58459456456828, precision: 93.79243120983274, recall: 95.39025299399678, loss: 0.04104639045533439\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccfbffb270964732adb698574917313e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25] - Loss: 0.0180\n",
      "name: train, f1: 94.69719170190535, precision: 93.92456739310836, recall: 95.48263266922345, loss: 0.04019742836018451\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b8b43add504725b0e405b7a65433c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25] - Loss: 0.0160\n",
      "name: train, f1: 94.80815503897226, precision: 94.05262885868797, recall: 95.57591782238157, loss: 0.03936398553587851\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf53e0cacb4d4ac681c218285adb43c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25] - Loss: 0.0149\n",
      "name: train, f1: 94.9132865497938, precision: 94.17475147361061, recall: 95.66349662909211, loss: 0.03856768512052801\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6c5dbf4925446b8bbec67f70d85373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25] - Loss: 0.0148\n",
      "name: train, f1: 95.01543084544791, precision: 94.29200416502549, recall: 95.75004389155025, loss: 0.037801812855466244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "106c83abe992440092d38ee6f2aea9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25] - Loss: 0.0137\n",
      "name: train, f1: 95.11051029021465, precision: 94.40367462547233, recall: 95.82801049097533, loss: 0.03708856678931319\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698c387ea7a048cab594ddbd96c659ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25] - Loss: 0.0140\n",
      "name: train, f1: 95.20354432856016, precision: 94.51010464412781, recall: 95.90723504027328, loss: 0.03638357081493175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1dafa46198f493c8ed056f0f8c2c47d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/25] - Loss: 0.0130\n",
      "name: train, f1: 95.29502730480922, precision: 94.6155243370815, recall: 95.98436088440275, loss: 0.03569285177138105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b313b144e9574764b5d8bd8e75db2846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25] - Loss: 0.0129\n",
      "name: train, f1: 95.38196490637291, precision: 94.71502188464731, recall: 96.05836719615812, loss: 0.035038427038201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255acd80f83c4dcbb644e6d8586b8a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25] - Loss: 0.0122\n",
      "name: train, f1: 95.46743444933671, precision: 94.81401975650537, recall: 96.12991770668118, loss: 0.03439770329748724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5021ce8047be4028a51e5ad19d9203f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/469 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25] - Loss: 0.0130\n",
      "name: train, f1: 95.54805925676884, precision: 94.90548813200849, recall: 96.19939093474534, loss: 0.0337908519162668\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "gbilstm_model = GloveBiLSTM(output_dim=len(tag2idx), glove_embeddings=glove_embeddings).to(device)\n",
    "losses, vlosses, lrs = training_loop(*create_hyperparameters(gbilstm_model, 25), gbilstm_model, gtrain_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "62fc6161-9c7f-4074-b13f-461a51466953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models\\blstm2\n"
     ]
    }
   ],
   "source": [
    "models_dir = 'models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save the model state dictionary, overwriting any existing file\n",
    "model_path = os.path.join(models_dir, 'blstm2.pt')\n",
    "torch.save(gbilstm_model.state_dict(), model_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53bc2581-2574-4271-b576-16b94f445740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: test, f1: 95.53320150832337, precision: 94.89385925895897, recall: 96.1812172626781, loss: 0.034131143978649976\n"
     ]
    }
   ],
   "source": [
    "# F1, precision, and recall result for eval\n",
    "f1 = eval_dataloader(gval_loader, gbilstm_model.eval(), loss_fn=loss_fn, name='Dev', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "928f34af-b0a8-4d7a-bdb9-6bde95b31c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_predictions(gval_loader, gbilstm_model, idx2tag, dataset['validation'], 'dev2.out')\n",
    "process_predictions(gtest_loader, gbilstm_model, idx2tag, test_dataset, 'test2.out')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
